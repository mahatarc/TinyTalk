{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Classification using Wav2Vec2 (Nepali Speech)\n",
    "\n",
    "This notebook presents an end-to-end pipeline for **audio classification using the Wav2Vec2 model**, with a focus on **Nepali speech data**.  \n",
    "It covers key stages including **dataset exploration, audio preprocessing, model fine-tuning, and evaluation**.\n",
    "\n",
    "The objective is to demonstrate how self-supervised speech models like Wav2Vec2 can be effectively adapted for **low-resource languages such as Nepali** to support tasks like speech understanding and language technology development.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install datasets transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-20T09:56:33.894207Z",
     "iopub.status.busy": "2025-03-20T09:56:33.893892Z",
     "iopub.status.idle": "2025-03-20T09:56:38.159715Z",
     "shell.execute_reply": "2025-03-20T09:56:38.158797Z",
     "shell.execute_reply.started": "2025-03-20T09:56:33.894183Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob\n",
    "import torchaudio\n",
    "import os\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:56:38.161788Z",
     "iopub.status.busy": "2025-03-20T09:56:38.161342Z",
     "iopub.status.idle": "2025-03-20T09:56:57.330476Z",
     "shell.execute_reply": "2025-03-20T09:56:57.329566Z",
     "shell.execute_reply.started": "2025-03-20T09:56:38.161763Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:56:57.332377Z",
     "iopub.status.busy": "2025-03-20T09:56:57.331726Z",
     "iopub.status.idle": "2025-03-20T09:56:57.336051Z",
     "shell.execute_reply": "2025-03-20T09:56:57.335229Z",
     "shell.execute_reply.started": "2025-03-20T09:56:57.332354Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Audio Dataset\n",
    "We begin by loading the audio dataset to understand its structure, labels, and sample distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:56:57.337148Z",
     "iopub.status.busy": "2025-03-20T09:56:57.336842Z",
     "iopub.status.idle": "2025-03-20T09:56:57.370496Z",
     "shell.execute_reply": "2025-03-20T09:56:57.369672Z",
     "shell.execute_reply.started": "2025-03-20T09:56:57.337121Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_audio_dataset(root_dir):\n",
    "    data = {\"audio\": [], \"label\": []}\n",
    "    label_map = {folder: idx for idx, folder in enumerate(sorted(os.listdir(root_dir)))}\n",
    "\n",
    "    for folder, label_idx in label_map.items():\n",
    "        folder_path = os.path.join(root_dir, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for file_name in os.listdir(folder_path):\n",
    "                if file_name.endswith(('.wav', '.flac')):  # Ensure compatibility\n",
    "                    file_path = os.path.join(folder_path, file_name)\n",
    "                    try:\n",
    "                        # Load audio\n",
    "                        waveform, sample_rate = torchaudio.load(file_path)\n",
    "\n",
    "                        # Convert to mono if stereo\n",
    "                        if waveform.shape[0] > 1:\n",
    "                            waveform = waveform.mean(dim=0)\n",
    "\n",
    "                        # Resample to 16kHz\n",
    "                        if sample_rate != 16000:\n",
    "                            waveform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)(waveform)\n",
    "\n",
    "                        # Convert tensor to NumPy and flatten\n",
    "                        waveform = waveform.numpy().flatten().tolist()\n",
    "\n",
    "                        data[\"audio\"].append(waveform)\n",
    "                        data[\"label\"].append(label_idx)\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading {file_path}: {e}\")  # Debugging\n",
    "\n",
    "    # Convert to Hugging Face Dataset format\n",
    "    dataset = Dataset.from_dict(data)\n",
    "\n",
    "    return dataset, label_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:56:57.371791Z",
     "iopub.status.busy": "2025-03-20T09:56:57.371455Z",
     "iopub.status.idle": "2025-03-20T09:57:46.587392Z",
     "shell.execute_reply": "2025-03-20T09:57:46.586494Z",
     "shell.execute_reply.started": "2025-03-20T09:56:57.371761Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset, label_map = load_audio_dataset('/kaggle/input/audiodataset/Dataset_Arc')\n",
    "\n",
    "# Print class mappings\n",
    "print(f\"Class to Label Mapping: {label_map}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Audio Waveform\n",
    "To better understand the raw audio signal, we visualize the waveform of a sample audio file from the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:57:46.589785Z",
     "iopub.status.busy": "2025-03-20T09:57:46.589550Z",
     "iopub.status.idle": "2025-03-20T09:57:59.569785Z",
     "shell.execute_reply": "2025-03-20T09:57:59.568875Z",
     "shell.execute_reply.started": "2025-03-20T09:57:46.589766Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "\n",
    "# Path to your audio file\n",
    "file_path = '/kaggle/input/audiodataset/Dataset_Arc/Eight/eight-2018-05-30T11_28_25.746Z.wav'  # Replace with the path to your audio file\n",
    "\n",
    "# Load audio using librosa\n",
    "waveform, sample_rate = librosa.load(file_path, sr=16000)  # Resample to 16kHz directly\n",
    "\n",
    "# Debugging: Check waveform shape and sample rate\n",
    "print(f\"Waveform shape: {waveform.shape}\")\n",
    "print(f\"Sample rate: {sample_rate}\")\n",
    "\n",
    "# Check if waveform is non-empty before plotting\n",
    "if waveform.size > 0:\n",
    "    # Plot the waveform\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.waveshow(waveform, sr=sample_rate)\n",
    "    plt.title(f\"Waveform for Audio: {file_path}\")\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"The waveform is empty. Check the audio file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Wav2vec2Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:57:59.572155Z",
     "iopub.status.busy": "2025-03-20T09:57:59.571586Z",
     "iopub.status.idle": "2025-03-20T09:58:03.284616Z",
     "shell.execute_reply": "2025-03-20T09:58:03.283975Z",
     "shell.execute_reply.started": "2025-03-20T09:57:59.572132Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the audio in batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:58:03.285709Z",
     "iopub.status.busy": "2025-03-20T09:58:03.285412Z",
     "iopub.status.idle": "2025-03-20T09:58:35.277479Z",
     "shell.execute_reply": "2025-03-20T09:58:35.276757Z",
     "shell.execute_reply.started": "2025-03-20T09:58:03.285678Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "max_length = 32000\n",
    "\n",
    "def preprocess_function(batch):\n",
    "    # Extract the list of audio waveforms and labels\n",
    "    audio_list = batch[\"audio\"]  # List of audio arrays\n",
    "    labels_list = batch[\"label\"]  # List of labels\n",
    "\n",
    "    # Process audio using the Wav2Vec2 processor\n",
    "    input_values = processor(\n",
    "        audio_list, return_tensors=\"pt\", sampling_rate=16000, truncation=True, \n",
    "        padding=\"max_length\", max_length=max_length\n",
    "    ).input_values  # This will be a tensor of shape (batch_size, max_length)\n",
    "\n",
    "    # Convert labels to tensors\n",
    "    labels_tensor = torch.tensor(labels_list)  # Convert label list to tensor\n",
    "    \n",
    "    return {\"input_values\": input_values, \"labels\": labels_tensor}\n",
    "\n",
    "# Apply preprocessing in batches\n",
    "dataset_mapped = dataset.map(preprocess_function, batched=True, remove_columns=[\"audio\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:58:35.278589Z",
     "iopub.status.busy": "2025-03-20T09:58:35.278331Z",
     "iopub.status.idle": "2025-03-20T09:58:35.283091Z",
     "shell.execute_reply": "2025-03-20T09:58:35.282404Z",
     "shell.execute_reply.started": "2025-03-20T09:58:35.278569Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset_mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:58:35.284024Z",
     "iopub.status.busy": "2025-03-20T09:58:35.283780Z",
     "iopub.status.idle": "2025-03-20T09:58:35.301329Z",
     "shell.execute_reply": "2025-03-20T09:58:35.300604Z",
     "shell.execute_reply.started": "2025-03-20T09:58:35.283998Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "len(label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split in the ratio 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:58:35.302275Z",
     "iopub.status.busy": "2025-03-20T09:58:35.302023Z",
     "iopub.status.idle": "2025-03-20T09:58:35.322088Z",
     "shell.execute_reply": "2025-03-20T09:58:35.321409Z",
     "shell.execute_reply.started": "2025-03-20T09:58:35.302255Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Split the dataset into train and test sets (80% train, 20% test)\n",
    "dataset_split = dataset_mapped.train_test_split(test_size=0.2, seed=42)  \n",
    "\n",
    "# Extract train and test datasets\n",
    "train_dataset = dataset_split[\"train\"]\n",
    "test_dataset = dataset_split[\"test\"]\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define evaluation metrics for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:58:35.323035Z",
     "iopub.status.busy": "2025-03-20T09:58:35.322787Z",
     "iopub.status.idle": "2025-03-20T09:58:39.126788Z",
     "shell.execute_reply": "2025-03-20T09:58:39.125774Z",
     "shell.execute_reply.started": "2025-03-20T09:58:35.323016Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:58:39.128415Z",
     "iopub.status.busy": "2025-03-20T09:58:39.128025Z",
     "iopub.status.idle": "2025-03-20T09:58:44.722466Z",
     "shell.execute_reply": "2025-03-20T09:58:44.721537Z",
     "shell.execute_reply.started": "2025-03-20T09:58:39.128382Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:58:44.723776Z",
     "iopub.status.busy": "2025-03-20T09:58:44.723449Z",
     "iopub.status.idle": "2025-03-20T09:58:46.501181Z",
     "shell.execute_reply": "2025-03-20T09:58:46.500325Z",
     "shell.execute_reply.started": "2025-03-20T09:58:44.723734Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "# Load accuracy metric\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:58:46.502317Z",
     "iopub.status.busy": "2025-03-20T09:58:46.502042Z",
     "iopub.status.idle": "2025-03-20T09:58:46.508454Z",
     "shell.execute_reply": "2025-03-20T09:58:46.507552Z",
     "shell.execute_reply.started": "2025-03-20T09:58:46.502297Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from transformers import  TrainerCallback\n",
    "\n",
    "class CustomCallback(TrainerCallback):\n",
    "    \n",
    "    def __init__(self, trainer) -> None:\n",
    "        super().__init__()\n",
    "        self._trainer = trainer\n",
    "        self.train_accuracies = []  \n",
    "        self.eval_accuracies = []  \n",
    "    \n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        if control.should_evaluate:\n",
    "            \n",
    "            control_copy = deepcopy(control)\n",
    "        \n",
    "            train_metrics = self._trainer.evaluate(eval_dataset=self._trainer.train_dataset, metric_key_prefix=\"train\")\n",
    "            \n",
    "            eval_metrics = self._trainer.evaluate(eval_dataset=self._trainer.eval_dataset, metric_key_prefix=\"eval\")\n",
    "     \n",
    "            train_accuracy = train_metrics.get('train_accuracy', None)\n",
    "            eval_accuracy = eval_metrics.get('eval_accuracy', None)\n",
    "    \n",
    "            if train_accuracy is not None:\n",
    "                self.train_accuracies.append(train_accuracy)\n",
    "            if eval_accuracy is not None:\n",
    "                self.eval_accuracies.append(eval_accuracy)\n",
    "     \n",
    "            print(f\"Train Accuracy: {train_accuracy}\")\n",
    "            print(f\"Eval Accuracy: {eval_accuracy}\")\n",
    "            \n",
    "            return control_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Wav2Vec2 Model for Audio Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:58:46.509722Z",
     "iopub.status.busy": "2025-03-20T09:58:46.509429Z",
     "iopub.status.idle": "2025-03-20T09:58:49.667701Z",
     "shell.execute_reply": "2025-03-20T09:58:49.667012Z",
     "shell.execute_reply.started": "2025-03-20T09:58:46.509694Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import  Wav2Vec2ForSequenceClassification\n",
    "\n",
    "model = Wav2Vec2ForSequenceClassification.from_pretrained(\n",
    "    \"facebook/wav2vec2-base-960h\", num_labels=27\n",
    ")  \n",
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:58:49.668707Z",
     "iopub.status.busy": "2025-03-20T09:58:49.668496Z",
     "iopub.status.idle": "2025-03-20T09:58:49.672346Z",
     "shell.execute_reply": "2025-03-20T09:58:49.671518Z",
     "shell.execute_reply.started": "2025-03-20T09:58:49.668689Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T12:19:43.631526Z",
     "iopub.status.busy": "2025-03-20T12:19:43.631230Z",
     "iopub.status.idle": "2025-03-20T12:19:43.661473Z",
     "shell.execute_reply": "2025-03-20T12:19:43.660830Z",
     "shell.execute_reply.started": "2025-03-20T12:19:43.631504Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=500,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    eval_strategy=\"epoch\",  \n",
    "    save_strategy=\"epoch\",        \n",
    "    save_total_limit=1,            \n",
    "    gradient_accumulation_steps=4,  \n",
    "    lr_scheduler_type=\"linear\",\n",
    "    max_grad_norm=0.5,  \n",
    "    report_to=\"none\",\n",
    "    push_to_hub=False,\n",
    "    fp16=True,\n",
    "    load_best_model_at_end=True,    \n",
    "    metric_for_best_model=\"accuracy\", \n",
    "    greater_is_better=True,         \n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:58:49.797380Z",
     "iopub.status.busy": "2025-03-20T09:58:49.797067Z",
     "iopub.status.idle": "2025-03-20T09:58:50.097206Z",
     "shell.execute_reply": "2025-03-20T09:58:50.096470Z",
     "shell.execute_reply.started": "2025-03-20T09:58:49.797348Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=processor,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "custom_callback = CustomCallback(trainer)\n",
    "trainer.add_callback(custom_callback)\n",
    "\n",
    "train = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T12:26:12.570158Z",
     "iopub.status.busy": "2025-03-20T12:26:12.569791Z",
     "iopub.status.idle": "2025-03-20T12:26:12.747588Z",
     "shell.execute_reply": "2025-03-20T12:26:12.746690Z",
     "shell.execute_reply.started": "2025-03-20T12:26:12.570131Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train_accuracies = custom_callback.train_accuracies\n",
    "eval_accuracies = custom_callback.eval_accuracies\n",
    "\n",
    "epochs = range(1, len(train_accuracies) + 1)\n",
    "\n",
    "plt.plot(epochs, train_accuracies, label=\"Train Accuracy\")\n",
    "plt.plot(epochs, eval_accuracies, label=\"Eval Accuracy\")\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training and Evaluation Accuracy Over Epochs\")\n",
    "plt.legend() \n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T12:26:15.133759Z",
     "iopub.status.busy": "2025-03-20T12:26:15.133465Z",
     "iopub.status.idle": "2025-03-20T12:26:15.329836Z",
     "shell.execute_reply": "2025-03-20T12:26:15.329037Z",
     "shell.execute_reply.started": "2025-03-20T12:26:15.133736Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "history = trainer.state.log_history\n",
    "\n",
    "train_losses = []\n",
    "eval_losses = []\n",
    "epochs = []\n",
    "\n",
    "for log in history:\n",
    "    if \"loss\" in log:  \n",
    "        train_losses.append(log[\"loss\"])\n",
    "    if \"eval_loss\" in log:  \n",
    "        eval_losses.append(log[\"eval_loss\"])\n",
    "        epochs.append(log[\"epoch\"])  \n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(len(train_losses)), train_losses, label=\"Train Loss\")\n",
    "plt.plot(epochs, eval_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T12:26:20.793264Z",
     "iopub.status.busy": "2025-03-20T12:26:20.792979Z",
     "iopub.status.idle": "2025-03-20T12:26:21.873199Z",
     "shell.execute_reply": "2025-03-20T12:26:21.872376Z",
     "shell.execute_reply.started": "2025-03-20T12:26:20.793243Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save_pretrained(\"./fine_tuned_ASR_model\")\n",
    "processor.save_pretrained(\"./fine_tuned_ASR_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T12:26:24.123289Z",
     "iopub.status.busy": "2025-03-20T12:26:24.122994Z",
     "iopub.status.idle": "2025-03-20T12:26:42.753466Z",
     "shell.execute_reply": "2025-03-20T12:26:42.752573Z",
     "shell.execute_reply.started": "2025-03-20T12:26:24.123266Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.make_archive(\"/kaggle/working/fine_tuned_ASR_model\", 'zip', \"./fine_tuned_ASR_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T12:15:18.861827Z",
     "iopub.status.busy": "2025-03-20T12:15:18.861563Z",
     "iopub.status.idle": "2025-03-20T12:15:18.866657Z",
     "shell.execute_reply": "2025-03-20T12:15:18.865749Z",
     "shell.execute_reply.started": "2025-03-20T12:15:18.861795Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class_to_label= {'Eight': 0, 'Five': 1, 'Four': 2, 'Nine': 3, 'One': 4, 'Seven': 5, 'Six': 6, 'Three': 7, 'Two': 8, 'Zero': 9,\n",
    "                 'अ': 10, 'अं': 11, 'अः': 12, 'आ': 13, 'इ': 14, 'ई': 15, 'उ': 16, 'ऊ': 17,\n",
    "                 'ए': 18, 'ऐ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26}\n",
    "\n",
    "index_to_label = {v: k for k, v in class_to_label.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the fine tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T12:41:59.257143Z",
     "iopub.status.busy": "2025-03-20T12:41:59.256822Z",
     "iopub.status.idle": "2025-03-20T12:41:59.352643Z",
     "shell.execute_reply": "2025-03-20T12:41:59.351766Z",
     "shell.execute_reply.started": "2025-03-20T12:41:59.257117Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_path = \"/kaggle/input/fine_tuned_asr_model/transformers/default/1\"  \n",
    "processor = Wav2Vec2Processor.from_pretrained(model_path)\n",
    "model = Wav2Vec2ForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict using fine_tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T12:42:04.107260Z",
     "iopub.status.busy": "2025-03-20T12:42:04.106971Z",
     "iopub.status.idle": "2025-03-20T12:42:04.113097Z",
     "shell.execute_reply": "2025-03-20T12:42:04.112039Z",
     "shell.execute_reply.started": "2025-03-20T12:42:04.107237Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 32000\n",
    "\n",
    "def predict_audio(audio_path):\n",
    "    waveform, sample_rate = torchaudio.load(audio_path)\n",
    "\n",
    "    if waveform.shape[0] > 1:\n",
    "        waveform = waveform.mean(dim=0)\n",
    "\n",
    "    if sample_rate != 16000:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
    "        waveform = resampler(waveform)\n",
    "\n",
    "    waveform = waveform.numpy().flatten().tolist()\n",
    "\n",
    "    input_values = processor(\n",
    "        waveform, return_tensors=\"pt\", sampling_rate=16000,\n",
    "        truncation=True, padding=\"max_length\", max_length=MAX_LENGTH\n",
    "    ).input_values\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_values)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predicted_id = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    predicted_label = index_to_label.get(predicted_id, \"Unknown Label (Out of Range)\")\n",
    "\n",
    "    return predicted_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T12:44:19.862474Z",
     "iopub.status.busy": "2025-03-20T12:44:19.862157Z",
     "iopub.status.idle": "2025-03-20T12:44:20.079116Z",
     "shell.execute_reply": "2025-03-20T12:44:20.078246Z",
     "shell.execute_reply.started": "2025-03-20T12:44:19.862448Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "audio_path = \"/kaggle/input/test-datasets/nga.wav\"  \n",
    "predicted_label = predict_audio(audio_path)\n",
    "print(f\"Predicted Label: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T12:44:23.306293Z",
     "iopub.status.busy": "2025-03-20T12:44:23.306012Z",
     "iopub.status.idle": "2025-03-20T12:44:23.310212Z",
     "shell.execute_reply": "2025-03-20T12:44:23.309371Z",
     "shell.execute_reply.started": "2025-03-20T12:44:23.306273Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T12:44:48.800541Z",
     "iopub.status.busy": "2025-03-20T12:44:48.800259Z",
     "iopub.status.idle": "2025-03-20T12:44:48.806800Z",
     "shell.execute_reply": "2025-03-20T12:44:48.805917Z",
     "shell.execute_reply.started": "2025-03-20T12:44:48.800518Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "model_dir = '/kaggle/input/fine_tuned_asr_model/transformers/default/1'\n",
    "print(os.listdir(model_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T12:44:53.814125Z",
     "iopub.status.busy": "2025-03-20T12:44:53.813807Z",
     "iopub.status.idle": "2025-03-20T12:45:09.428990Z",
     "shell.execute_reply": "2025-03-20T12:45:09.428032Z",
     "shell.execute_reply.started": "2025-03-20T12:44:53.814099Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "X_test = torch.stack([torch.tensor(example[\"input_values\"]) for example in test_dataset]) \n",
    "y_test = torch.tensor([example[\"labels\"] for example in test_dataset])  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T12:45:12.403811Z",
     "iopub.status.busy": "2025-03-20T12:45:12.403491Z",
     "iopub.status.idle": "2025-03-20T12:47:07.750802Z",
     "shell.execute_reply": "2025-03-20T12:47:07.749798Z",
     "shell.execute_reply.started": "2025-03-20T12:45:12.403777Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "with torch.no_grad(): \n",
    "    outputs = model(X_test)  \n",
    "\n",
    "    logits = outputs.logits\n",
    "\n",
    "    predicted_labels = torch.argmax(logits, dim=1).numpy() \n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test.numpy(), predicted_labels)\n",
    "\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test.numpy(), predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T12:47:07.752470Z",
     "iopub.status.busy": "2025-03-20T12:47:07.752163Z",
     "iopub.status.idle": "2025-03-20T12:47:08.037798Z",
     "shell.execute_reply": "2025-03-20T12:47:08.036970Z",
     "shell.execute_reply.started": "2025-03-20T12:47:07.752447Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T12:47:08.039906Z",
     "iopub.status.busy": "2025-03-20T12:47:08.039259Z",
     "iopub.status.idle": "2025-03-20T12:47:08.045539Z",
     "shell.execute_reply": "2025-03-20T12:47:08.044736Z",
     "shell.execute_reply.started": "2025-03-20T12:47:08.039871Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class_to_label_mapping = {\n",
    "    'Eight': 0, 'Five': 1, 'Four': 2, 'Nine': 3, 'One': 4, 'Seven': 5,\n",
    "    'Six': 6, 'Three': 7, 'Two': 8, 'Zero': 9, 'अ': 10, 'अं': 11,\n",
    "    'अः': 12, 'आ': 13, 'इ': 14, 'ई': 15, 'उ': 16, 'ऊ': 17, 'ए': 18,\n",
    "    'ऐ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25,\n",
    "    'ङ': 26\n",
    "}\n",
    "\n",
    "\n",
    "class_names = list(class_to_label_mapping.keys())\n",
    "\n",
    "\n",
    "print(class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T12:47:08.046845Z",
     "iopub.status.busy": "2025-03-20T12:47:08.046500Z",
     "iopub.status.idle": "2025-03-20T12:47:09.292040Z",
     "shell.execute_reply": "2025-03-20T12:47:09.291206Z",
     "shell.execute_reply.started": "2025-03-20T12:47:08.046815Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
    "            xticklabels=[str(i) for i in range(conf_matrix.shape[1])],\n",
    "            yticklabels=[str(i) for i in range(conf_matrix.shape[0])])\n",
    "\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix Heatmap')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6784713,
     "sourceId": 10914301,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6922116,
     "sourceId": 11103756,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 273057,
     "modelInstanceId": 251583,
     "sourceId": 293727,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
